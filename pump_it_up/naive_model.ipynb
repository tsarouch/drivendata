{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports libs etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('/Users/charilaostsarouchas/tsarouch_github/drivendata/pump_it_up')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "\n",
    "from config import data_path, train_values_file, train_labels_file, test_values_file\n",
    "from reader import get_train_data_spark_df, get_test_data_spark_df\n",
    "from ml_features import get_index_string_d, get_string_indexed_df\n",
    "from ml_data_structures import get_supervised_learning_df\n",
    "from dataframe_helper import change_dataframe_column_type\n",
    "\n",
    "#from pyspark.sql.types import StringType, IntegerType, FloatType\n",
    "#from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = get_train_data_spark_df(sqlContext)\n",
    "df_test = get_test_data_spark_df(sqlContext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_SL = get_supervised_learning_df(df_train, 'status_group', ['gps_height', 'latitude', 'longitude'])\n",
    "df_train_SL = get_string_indexed_df(df_train_SL, ['label'])\n",
    "label_index_string_d = get_index_string_d(df_train_SL, 'label')\n",
    "# Run random forest\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(numTrees=3,\n",
    "                            maxDepth=2, \n",
    "                            labelCol=\"label_index\",\n",
    "                            seed=42)\n",
    "model = rf.fit(df_train_SL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Random Forest on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test_SL = get_supervised_learning_df(df_test, 'id', ['gps_height', 'latitude', 'longitude'], label_name='id')\n",
    "predictions_df = model.transform(df_test_SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "predictions_df = predictions_df.withColumn(\n",
    "            'status_group', \n",
    "            udf(lambda x : label_index_string_d[x], StringType())\n",
    "            (predictions_df.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge to the exact format to be uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df = change_dataframe_column_type(predictions_df, 'id', 'int')\n",
    "\n",
    "predictions_pdf = \\\n",
    "    predictions_df\\\n",
    "    .select(predictions_df['id'], predictions_df['status_group'])\\\n",
    "    .toPandas()\n",
    "original_test_df = pd.read_csv(test_values_file, usecols=['id'])\n",
    "\n",
    "# Merge to the required ids (sorted as in the test file) and dump to csv\n",
    "pd.merge(original_test_df, predictions_pdf, on='id').to_csv(os.path.join(data_path, 'results.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
